{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES\n",
    "import glob\n",
    "from scipy.misc import imread\n",
    "import numpy as np\n",
    "import time as time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TRAINING AND TESTING LISTS\n",
    "X_test = []\n",
    "Y_test = []\n",
    "X_train = []\n",
    "Y_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List of files for non faces in train\n",
    "non_faces_files_list_train = (glob.glob(\"/Users/crystinrodrick/PycharmProjects/MachineLearning2018/train/non-face/*.pgm\"))\n",
    "\n",
    "# BUILD UP TRAINING MATRICES\n",
    "for file in non_faces_files_list_train:\n",
    "\n",
    "        imgData = imread(file)\n",
    "        x = imgData.ravel()\n",
    "        X_train.append(x)\n",
    "        Y_train.append(0) # NON-Face = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List of files for faces in train\n",
    "faces_files_list_train = (glob.glob(\"/Users/crystinrodrick/PycharmProjects/MachineLearning2018/train/face/*.pgm\"))\n",
    "\n",
    "# BUILD UP TRAINING MATRICES\n",
    "for file in faces_files_list_train:\n",
    "\n",
    "        imgData = imread(file)\n",
    "        x = imgData.ravel()\n",
    "        X_train.append(x)\n",
    "        Y_train.append(1) # Face = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6977, 361)\n",
      "(6977,)\n"
     ]
    }
   ],
   "source": [
    "# CHECK THAT WE HAVE THE PROPER AMOUNT\n",
    "xs_train = np.array(X_train)\n",
    "#print(len(xs_train[0]))\n",
    "ys_train = np.array(Y_train)\n",
    "print(xs_train.shape)\n",
    "print(ys_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FILES TO GRAB\n",
    "faces_files_list_test = (glob.glob(\"/Users/crystinrodrick/PycharmProjects/MachineLearning2018/test/face/*.pgm\"))\n",
    "\n",
    "# BUILD UP TESTING MATRICES\n",
    "for file in faces_files_list_test:\n",
    "\n",
    "        imgData = imread(file)\n",
    "        x = imgData.ravel()\n",
    "        X_test.append(x)\n",
    "        Y_test.append(1) # Face = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List of files for non faces in test\n",
    "non_faces_files_list_test = (glob.glob(\"/Users/crystinrodrick/PycharmProjects/MachineLearning2018/test/non-face/*.pgm\"))\n",
    "\n",
    "# BUILD UP TESTING MATRICES\n",
    "for file in non_faces_files_list_test:\n",
    "\n",
    "        imgData = imread(file)\n",
    "        x = imgData.ravel()\n",
    "        X_test.append(x)\n",
    "        Y_test.append(0) # NON-Face = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24045, 361)\n",
      "(24045,)\n"
     ]
    }
   ],
   "source": [
    "xs_test = np.array(X_test)\n",
    "ys_test = np.array(Y_test)\n",
    "#print(len(X_test))\n",
    "print(xs_test.shape)\n",
    "print(ys_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## PROBABILITIES OF FACE AND PROB OF NON FACE\n",
    "def p_of_face():\n",
    "    return len(faces_files_list_train) / (len(faces_files_list_train) + len(non_faces_files_list_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def p_of_non_face():\n",
    "    return len(non_faces_files_list_train) / (len(faces_files_list_train) + len(non_faces_files_list_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TO BE USED FOR ROC\n",
    "true_positives = []\n",
    "false_positives = []\n",
    "true_negatives = []\n",
    "false_negatives = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DETERMINE THE STATS \n",
    "def true_positive():\n",
    "    tp = 0\n",
    "    for i in range(len(Y_test)):\n",
    "        \n",
    "        if Y_pred[i] == 0 and int(Y_test[i]) == 0:\n",
    "            tp += 1\n",
    "            true_positives.append(1)\n",
    "    #print(\"TP: \", tp)\n",
    "    return tp\n",
    "\n",
    "def false_positive():\n",
    "    fp = 0\n",
    "    for i in range(len(Y_test)):\n",
    "        if Y_pred[i] == 0 and int(Y_test[i]) == 1:\n",
    "            fp += 1\n",
    "            false_positives.append(1)\n",
    "    #print(\"FP:\", fp)\n",
    "    return fp\n",
    "\n",
    "def true_negative():\n",
    "    tn = 0\n",
    "    for i in range(len(Y_test)):\n",
    "        if Y_pred[i] == 1 and int(Y_test[i]) == 1:\n",
    "            tn += 1\n",
    "            true_negatives.append(1)\n",
    "    #print(\"TN:\", tn)\n",
    "    return tn\n",
    "\n",
    "def false_negative():\n",
    "    fn = 0\n",
    "    for i in range(len((Y_test))):\n",
    "        if Y_pred[i] == 1 and int(Y_test[i]) == 0:\n",
    "            fn += 1\n",
    "            false_negatives.append(1)\n",
    "    #print(\"FN: \", fn)\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### REPORT ACCURACY, PRECISION, RECALL, F1-SCORE ######\n",
    "def accuracy():\n",
    "    # Accuracy = (true positive + true negative) / (true positive + true negative + false positive + false negative)\n",
    "    try:\n",
    "        x =(true_positive() + true_negative()) / (true_positive() + true_negative() + false_positive() + false_negative())\n",
    "        return x\n",
    "    except ZeroDivisionError:\n",
    "        print(\"Use LaPlace Method, dum dum\")\n",
    "\n",
    "def precision():\n",
    "    # Precision = True positive / (True positive + False Positive)\n",
    "    try:\n",
    "        x = int(true_positive()) / (int(true_positive()) + int(false_positive()))\n",
    "        return x\n",
    "    except ZeroDivisionError:\n",
    "        print(\"Use LaPlace Method, dum dum\")\n",
    "\n",
    "def recall():\n",
    "    # Recall = True Positive / (True Positive + False Negative)\n",
    "    try:\n",
    "        return true_positive() / int(true_positive() + false_negative())\n",
    "    except ZeroDivisionError:\n",
    "        print(\"NOT ENOUGH INFO\")\n",
    "\n",
    "\n",
    "def f1_score():\n",
    "    # F1-score = 2 * ((Precision * Recall) / (Precision + Recall))\n",
    "    return 2 * ((precision() * recall()) / precision() + recall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TRANSPOSE THE TRAIN AND TEST SET\n",
    "inverse_xs_train = xs_train.T \n",
    "inverse_xs_test = xs_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PROBABILITIES LIST\n",
    "probs_of_a1c0 = []\n",
    "probs_of_a2c0 = []\n",
    "probs_of_a3c0 = []\n",
    "probs_of_a4c0 = []\n",
    "probs_of_a1c1 = []\n",
    "probs_of_a2c1 = []\n",
    "probs_of_a3c1 = []\n",
    "probs_of_a4c1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6977\n"
     ]
    }
   ],
   "source": [
    "print(len(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### TRY TO USE A GRAB THAT CAN EASILY DISTINGUISH BOTH SIDES\n",
    "Y_pred = []\n",
    "col = 0\n",
    "for l in range(361):\n",
    "    x =inverse_xs_train[col]\n",
    "    a1c0 = []\n",
    "    a2c0 = []\n",
    "    a3c0 = []\n",
    "    a4c0 = []\n",
    "    a1c1 = []\n",
    "    a2c1 = []\n",
    "    a3c1 = []\n",
    "    a4c1 = []\n",
    "    number = 0\n",
    "    for item in x:\n",
    "        #print(item, Y_train[number])\n",
    "        ####30,60,110,256\n",
    "        if item <= 20 and int(Y_train[number]) == 0:\n",
    "            a1c0.append(1)\n",
    "        elif item <= 20 and int(Y_train[number]) == 1:\n",
    "            a1c1.append(1)\n",
    "        elif item > 20 and item <= 80 and int(Y_train[number]) == 0:\n",
    "            a2c0.append(1)\n",
    "        elif item > 20 and item <= 80 and int(Y_train[number]) == 1:\n",
    "            a2c1.append(1)\n",
    "        elif item > 80 and item <= 120 and int(Y_train[number]) == 0:\n",
    "            a3c0.append(1)\n",
    "        elif item > 80 and item <= 120 and int(Y_train[number]) == 1:\n",
    "            a3c1.append(1)\n",
    "        elif item > 120 and item <= 256 and int(Y_train[number]) == 0:\n",
    "            a4c0.append(1)\n",
    "        elif item > 120 and item <= 256 and int(Y_train[number]) == 1:\n",
    "            a4c1.append(1)\n",
    "        number += 1\n",
    "        #print(number)\n",
    "    col +=1\n",
    "    \n",
    "    probs_of_a1c0.append(sum(a1c0) / len(non_faces_files_list_train))\n",
    "    probs_of_a2c0.append(sum(a2c0) / len(non_faces_files_list_train))\n",
    "    probs_of_a3c0.append(sum(a3c0) / len(non_faces_files_list_train))\n",
    "    probs_of_a4c0.append(sum(a4c0) / len(non_faces_files_list_train))\n",
    "    probs_of_a1c1.append(sum(a1c1) / len(faces_files_list_train))\n",
    "    probs_of_a2c1.append(sum(a2c1) / len(faces_files_list_train))\n",
    "    probs_of_a3c1.append(sum(a3c1) / len(faces_files_list_train))\n",
    "    probs_of_a4c1.append(sum(a4c1) / len(faces_files_list_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1171943711521548\n",
      "0.3087071240105541\n",
      "0.22977132805628847\n",
      "0.34432717678100266\n",
      "0.04240428159736517\n",
      "0.4664470975710169\n",
      "0.27254013997529847\n",
      "0.21860848085631948\n"
     ]
    }
   ],
   "source": [
    "# CHECK THAT PROBABILITIES ADD UP TO ONE\n",
    "print(probs_of_a1c0[0])\n",
    "print(probs_of_a2c0[0])\n",
    "print(probs_of_a3c0[0])\n",
    "print(probs_of_a4c0[0])\n",
    "print(probs_of_a1c1[0])\n",
    "print(probs_of_a2c1[0])\n",
    "print(probs_of_a3c1[0])\n",
    "print(probs_of_a4c1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "prob_log_vals_for_face = []\n",
    "prob_log_vals_for_non_face = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING TIME FOR NAIVE BAYES:  90.57314991950989\n"
     ]
    }
   ],
   "source": [
    "from time import time \n",
    "counter = 0\n",
    "start_time_bayes = time()\n",
    "for row in X_test:\n",
    "    ## THIS WILL ADD PROBS FROM TEST SET BASED OFF OF TRAINING SET\n",
    "    probs_of_face = []\n",
    "    probs_of_non_face = []\n",
    "    col = 0\n",
    "    for _ in range(361):\n",
    "        \n",
    "        if row[col] <= 20:\n",
    "            if probs_of_a1c0[col] != 0 and probs_of_a1c1[col] != 0:\n",
    "                probs_of_non_face.append(math.log(probs_of_a1c0[col]))#probs_of_a1c0[col])#\n",
    "                probs_of_face.append(math.log(probs_of_a1c1[col]))#probs_of_a1c1[col])#\n",
    "            else:\n",
    "                probs_of_non_face.append(math.log(0.12))\n",
    "                probs_of_face.append(math.log(0.12))\n",
    "        if row[col] > 20 and row[col] <= 80:\n",
    "            if probs_of_a2c0[col] != 0 and probs_of_a2c1[col] != 0:\n",
    "                probs_of_non_face.append(math.log(probs_of_a2c0[col]))#probs_of_a2c0[col])#\n",
    "                probs_of_face.append(math.log(probs_of_a2c1[col]))#probs_of_a2c1[col])#\n",
    "            else:\n",
    "                probs_of_non_face.append(math.log(0.12))\n",
    "                probs_of_face.append(math.log(0.12))\n",
    "        if row[col] > 80 and row[col] <= 120:\n",
    "            if probs_of_a3c0[col] != 0 and probs_of_a3c1[col] != 0:\n",
    "                probs_of_non_face.append(math.log(probs_of_a3c0[col]))#probs_of_a3c0[col])#\n",
    "                probs_of_face.append(math.log(probs_of_a3c1[col]))#probs_of_a3c1[col])#\n",
    "            else:\n",
    "                probs_of_non_face.append(math.log(0.12))\n",
    "                probs_of_face.append(math.log(0.12))\n",
    "        if row[col] > 120 and row[col] <= 256:\n",
    "            if probs_of_a4c0[col] != 0 and probs_of_a4c1[col] != 0:\n",
    "                probs_of_non_face.append(math.log(probs_of_a4c0[col]))#probs_of_a4c0[col])#\n",
    "                probs_of_face.append(math.log(probs_of_a4c1[col]))#probs_of_a4c1[col])#\n",
    "            else:\n",
    "                probs_of_non_face.append(math.log(0.12))\n",
    "                probs_of_face.append(math.log(0.12))\n",
    "        col += 1\n",
    "    face = math.log(p_of_face()) + sum(probs_of_face)#p_of_face() * np.prod(probs_of_face)## #\n",
    "    non_face = math.log(p_of_non_face()) + sum(probs_of_non_face)# #p_of_non_face() * np.prod(probs_of_non_face) #\n",
    "    \n",
    "    find_max_prob = []\n",
    "    find_max_prob.append(non_face)\n",
    "    find_max_prob.append(face)\n",
    "    prob_log_vals_for_non_face.append(non_face)\n",
    "    prob_log_vals_for_face.append(face)\n",
    "    if max(find_max_prob) == find_max_prob[0]:\n",
    "        Y_pred.append(0)\n",
    "    else:\n",
    "        Y_pred.append(1)\n",
    "    #print(find_max_prob, Y_test[counter])\n",
    "    \n",
    "    if Y_pred[counter] == 1 and Y_test[counter] == 1:\n",
    "        tp += 1\n",
    "    if Y_pred[counter] == 1 and Y_test[counter] == 0:\n",
    "        fp += 1\n",
    "    if Y_pred[counter] == 0 and Y_test[counter] == 1:\n",
    "        fn += 1\n",
    "    if Y_pred[counter] == 0 and Y_test[counter] == 0:\n",
    "        tn += 1\n",
    "    counter += 1\n",
    "end_time_bayes = time()\n",
    "print(\"RUNNING TIME FOR NAIVE BAYES: \", (end_time_bayes - start_time_bayes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY:  0.5376169681846538\n",
      "PRECISION:  0.9896218256152213\n",
      "F1_SCORE:  2.135833368684512\n",
      "RECALL:  0.533958342171128\n"
     ]
    }
   ],
   "source": [
    "print(\"ACCURACY: \", accuracy())\n",
    "print(\"PRECISION: \", precision())\n",
    "print(\"F1_SCORE: \", f1_score())\n",
    "print(\"RECALL: \", recall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TO BE USED FOR ROC\n",
    "true_positives_BGD = []\n",
    "false_positives_BGD = []\n",
    "true_negatives_BGD = []\n",
    "false_negatives_BGD = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####THE FOLLOWING IS BATCH GRADIENT DESCENT \n",
    "\n",
    "tp = []\n",
    "tn = []\n",
    "fp = []\n",
    "fn = []\n",
    "Y_pred = []\n",
    "def log_regression(X, y, nEpoch, alpha, lambdaVal):\n",
    "    w = np.random.uniform(size=(X.shape[1],))\n",
    "    \n",
    "    #previousLoss = +float('inf')\n",
    "    for epoch in np.arange(0, nEpoch):\n",
    "        hypo = expit(X.dot(w))\n",
    "        \n",
    "        error = hypo - y\n",
    "        \n",
    "        gradient = X.T.dot(error) - lambdaVal*w\n",
    "        if lambdaVal != 0:\n",
    "            gradient[0] = np.sum(error)\n",
    "        w = w - alpha*gradient\n",
    "        #print(\"epoch #{}, loss={:.7f}\".format(epoch+1, loss))\n",
    "        #print(hypo[epoch], y[epoch])\n",
    "        if hypo[epoch] == 0 and y[epoch] == 0:\n",
    "            tp.append(1)\n",
    "            true_positives_BGD.append(1)\n",
    "        if hypo[epoch] == 1 and y[epoch] == 1:\n",
    "            tn.append(1)\n",
    "            true_negatives_BGD.append(1)\n",
    "        if hypo[epoch] == 0 and y[epoch] == 1:\n",
    "            fp.append(1)\n",
    "            false_positives_BGD.append(1)\n",
    "        if hypo[epoch] == 1 and y[epoch] == 0:\n",
    "            fn.append(1)\n",
    "            false_negatives_BGD.append(1)\n",
    "        Y_pred.append(hypo)\n",
    "    print(\"BATCH GRADIENT DESCENT\")\n",
    "    # Accuracy = (true positive + true negative) / (true positive + true negative + false positive + false negative)\n",
    "    print(\"ACCURACY: \", (len(tp) + len(tn)) / (len(tp) + len(tn) + len(fp) + len(fn)))\n",
    "    # Precision = True positive / (True positive + False Positive)\n",
    "    precision = len(tp) / (len(tp) + len(fp))\n",
    "    print(\"PRECISION: \", precision)\n",
    "    # Recall = True Positive / (True Positive + False Negative)\n",
    "    recall = len(tp) / (len(tp) + len(fn))\n",
    "    print(\"RECALL: \", recall)   \n",
    "    # F1-score = 2 * ((Precision * Recall) / (Precision + Recall))\n",
    "    print(\"F1_SCORE: \", 2 * ((precision * recall) / (precision + recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH GRADIENT DESCENT\n",
      "ACCURACY:  0.529\n",
      "PRECISION:  0.5285285285285285\n",
      "RECALL:  1.0\n",
      "F1_SCORE:  0.6915520628683692\n",
      "TIME TO COMPUTE BATCH LOGISTIC REGRESSION:  55.19485306739807\n"
     ]
    }
   ],
   "source": [
    "####BATCH LOG REGRESSION - GRADIENT DESCENT\n",
    "start_time_blr = time()\n",
    "log_regression(xs_test, ys_test, 1000, 0.5, 1) \n",
    "end_time_blr = time()\n",
    "print(\"TIME TO COMPUTE BATCH LOGISTIC REGRESSION: \", (end_time_blr - start_time_blr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 24045\n"
     ]
    }
   ],
   "source": [
    "print(len(Y_pred), len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TO BE USED FOR ROC\n",
    "true_positives_SGD = []\n",
    "false_positives_SGD = []\n",
    "true_negatives_SGD = []\n",
    "false_negatives_SGD = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####THE FOLLOWING IS BATCH GRADIENT DESCENT \n",
    "tp = []\n",
    "tn = []\n",
    "fp = []\n",
    "fn = []\n",
    "Y_pred = []\n",
    "def log_regression_stochastic(X, y, nEpoch, alpha, lambdaVal=0):\n",
    "    w = np.random.uniform(size=(X.shape[1],))\n",
    "    \n",
    "    #previousLoss = +float('inf')\n",
    "    for epoch in np.arange(0, nEpoch):\n",
    "        hypo = expit(X.dot(w))\n",
    "        \n",
    "        error = hypo - y\n",
    "        \n",
    "        gradient = lambdaVal*w\n",
    "        if lambdaVal != 0:\n",
    "            gradient[0] = np.sum(error)\n",
    "        w = w - alpha*gradient\n",
    "        #print(\"epoch #{}, loss={:.7f}\".format(epoch+1, loss))\n",
    "        #print(hypo[epoch], y[epoch])\n",
    "        if hypo[epoch] == 0 and y[epoch] == 0:\n",
    "            tp.append(1)\n",
    "            true_positives_SGD.append(1)\n",
    "        if hypo[epoch] == 1 and y[epoch] == 1:\n",
    "            tn.append(1)\n",
    "            true_negatives_SGD.append(1)\n",
    "        if hypo[epoch] == 0 and y[epoch] == 1:\n",
    "            fp.append(1)\n",
    "            false_positives_SGD.append(1)\n",
    "        if hypo[epoch] == 1 and y[epoch] == 0:\n",
    "            fn.append(1)\n",
    "            false_negatives_SGD.append(1)\n",
    "        Y_pred.append(hypo)\n",
    "    print(\"STOCHASTIC GRADIENT DESCENT\")\n",
    "    # Accuracy = (true positive + true negative) / (true positive + true negative + false positive + false negative)\n",
    "    print(\"ACCURACY: \", (len(tp) + len(tn)) / (len(tp) + len(tn) + len(fp) + len(fn)))\n",
    "    # Precision = True positive / (True positive + False Positive)\n",
    "    precision = len(tp) / (len(tp) + len(fp))\n",
    "    print(\"PRECISION: \", precision)\n",
    "    # Recall = True Positive / (True Positive + False Negative)\n",
    "    recall = len(tp) / (len(tp) + len(fn))\n",
    "    print(\"RECALL: \", recall)   \n",
    "    # F1-score = 2 * ((Precision * Recall) / (Precision + Recall))\n",
    "    print(\"F1_SCORE: \", 2 * ((precision * recall) / (precision + recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STOCHASTIC GRADIENT DESCENT\n",
      "ACCURACY:  0.5332650972364381\n",
      "PRECISION:  0.5348595213319459\n",
      "RECALL:  0.982791586998088\n",
      "F1_SCORE:  0.6927223719676551\n",
      "TIME TO COMPUTE STOCHASTIC LOGISTIC REGRESSION:  28.779766082763672\n"
     ]
    }
   ],
   "source": [
    "start_time_slr = time()\n",
    "log_regression_stochastic(xs_test, ys_test, 1000, 0.1, 0.5) \n",
    "end_time_slr = time()\n",
    "print(\"TIME TO COMPUTE STOCHASTIC LOGISTIC REGRESSION: \", (end_time_slr - start_time_slr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
